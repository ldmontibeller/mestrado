{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMIwNGcmMR8dTcXgteseOhu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ldmontibeller/mestrado/blob/main/RN%26DL_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2025-04-10\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OMY0u-ejsbES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dúvidas\n",
        "*   Perceptron e Adaline\n",
        "*   Regressão Linear e Regressão Logística\n",
        "*   Diferenças nas funções de ativação\n",
        "*   Função objetivo? MSE e binary crossentropy\n",
        "*   Por que usamos derivadas para encontrar o erro?\n"
      ],
      "metadata": {
        "id": "ljxVVrFjvSuX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perceptron e Adaline\n",
        "Perceptron: Encontra qualquer reta que que classifica dois grupos\n",
        "\n",
        "Adaline: Econtra a melhor reta dada a função objetivo (redução de custo)"
      ],
      "metadata": {
        "id": "MA2SqFtJv5Rl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regressão linear\n",
        "\n",
        "Regressão linear é um perceptron com uma função de ativação linear $\\sigma$(x) = x, ou seja é uma função identidade que passa o valor computado na net input."
      ],
      "metadata": {
        "id": "2G-gA5Zdxn79"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss\n",
        "The loss function is a mathematical function that compares the predicted output to the actual output.\n",
        "The loss function's output is used to adjust the model's weights.\n",
        "A gente faz iterações até o modelo não conseguir mais diminuir o loss. Ou seja, tenta minimizar o loss."
      ],
      "metadata": {
        "id": "p-XShEKVJQex"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning rate\n",
        "Taxa de aprendizagem: é apenas um multiplicador η que diz a velocidade que o erro (gradiente negativo do loss) é aprimorado. Fator de escalamento do erro."
      ],
      "metadata": {
        "id": "82Ll1816KqK9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-lTJ8wd7RBot"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}