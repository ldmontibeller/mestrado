{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNCqMIZODFN1TiPD469t+jB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ldmontibeller/mestrado/blob/main/Logic_gates_tensorflow_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Portas lógicas com Redes Neurais\n",
        "Esse caderno visa o entendimento de soluções de referência como TensorFlow e Keras aplicando em simples exemplos de portas lógicas."
      ],
      "metadata": {
        "id": "Pe1sxEromWC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Introdução"
      ],
      "metadata": {
        "id": "B3s_EA9VETel"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importação das bibliotecas\n",
        "Keras é uma biblioteca de alto nível para TensorFlow, que já vem dentro do mesmo."
      ],
      "metadata": {
        "id": "Q-3yv-KjH1YL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i_gqL04ncO8y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Montagem do drive"
      ],
      "metadata": {
        "id": "ycMsniZwlcng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tWsbYiHbcoyA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "429e655e-0209-4427-bf98-a273baf7afac"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Porta lógica AND"
      ],
      "metadata": {
        "id": "XBEmDc0THVIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparando um dataset de um arquivo txt"
      ],
      "metadata": {
        "id": "UDZcwBiknN72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.genfromtxt('/content/drive/MyDrive/RC18EE---Intro-to-Deep-Learning-master/L03_perceptron/code/data/perceptron_and.txt', delimiter= '\\t')\n",
        "data"
      ],
      "metadata": {
        "id": "W9KEMIJDnK1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1338a98-b33a-434f-c0d7-6fd0a3f0e9ef"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sintaxe de arrays em numpy"
      ],
      "metadata": {
        "id": "gBqHsOmvoiw-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* : → Seleciona todas as linhas.\n",
        "* :2 → Seleciona as duas primeiras colunas (índices 0 e 1).\n",
        "* 2 → Seleciona a terceira coluna (índice 2)."
      ],
      "metadata": {
        "id": "3m14qVL6rYjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = data[:,:2], data[:,2]\n",
        "X, y"
      ],
      "metadata": {
        "id": "HPOUlexFptN6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "3a44af18-609b-45aa-f383-630dd0b8fd0c"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [1., 1.]]),\n",
              " array([0., 0., 0., 1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embaralhar dados\n",
        "Embaralhar dados torna o aprendizado do perceptron mais eficiente. [Explicação aqui](https://https://datascience.stackexchange.com/questions/24511/why-should-the-data-be-shuffled-for-machine-learning-tasks)"
      ],
      "metadata": {
        "id": "CeF5qcOznxkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_in_unison(a, b):\n",
        "  \"\"\"Shuffles two arrays in unison using the same permutation.\n",
        "\n",
        "  Args:\n",
        "    a: The first numpy array.\n",
        "    b: The second numpy array.\n",
        "\n",
        "  Returns:\n",
        "    A tuple containing the shuffled arrays.\n",
        "  \"\"\"\n",
        "  assert len(a) == len(b)  # Make sure arrays have the same length\n",
        "  p = np.random.permutation(len(a))  # Create a permutation of indices\n",
        "  return a[p], b[p]  # Apply the permutation to both arrays\n",
        "\n",
        "X, y = shuffle_in_unison(X, y)\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgbTiA71prJz",
        "outputId": "92b81c1c-48fc-4215-adb5-cd061b1c8e9a"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0.],\n",
              "        [1., 1.],\n",
              "        [1., 0.],\n",
              "        [0., 1.]]),\n",
              " array([0., 1., 0., 0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalização e separação de dados para validação cruzada\n",
        "Normalmente um conjunto de dados precisa ser normalizado e ter uma parte sua separada para utilizar um método de validação cruzada. A normalização faz com que os pesos sejam menores e mais fáceis de calcular, mais sobre [aqui](https://www.codecademy.com/article/normalization). Devido a natureza introdutória deste caderno não iremos abordar validação cruzada.\n",
        "\n",
        "OBS: Por algum motivo normalizar no caso da porta lógica está prejudicando o resultado. Ou o resultado também está saindo normalizado, o que não entendo completamente."
      ],
      "metadata": {
        "id": "WIipe0ZOEJDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# scaler = StandardScaler()\n",
        "# scaler.fit(X)\n",
        "\n",
        "# X = scaler.transform(X)\n",
        "\n",
        "# #A média precisa se aproximar de zero e o desvio padrão de 1\n",
        "\n",
        "# print('X mean', np.mean(X))\n",
        "# print('X standard deviation', np.std(X))\n",
        "\n",
        "X\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBqzmGFdr41Q",
        "outputId": "37099b96-1fc4-49e3-dbfc-83b3b9c53cd9"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Criando um modelo para rede neural"
      ],
      "metadata": {
        "id": "uiKzyOrX5uXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Formato de entrada da rede\n",
        "X_input = tf.keras.Input(shape=(X.shape[1],))\n",
        "\n",
        "#Formato da única camada de saída\n",
        "y_pred= tf.keras.layers.Dense(units=1, activation='sigmoid', kernel_initializer=\"zeros\", use_bias='yes')(X_input)\n",
        "\n",
        "#Criando o modelo com os formatos de entrada e saída\n",
        "model = tf.keras.Model(inputs=X_input, outputs=y_pred, name='AND_model')\n",
        "\n",
        "#Outra maneira de criar\n",
        "# model = tf.keras.Sequential(\n",
        "#     [\n",
        "#         tf.keras.layers.Dense(units=1, input_shape=(2,)),\n",
        "#         tf.keras.layers.Activation(tf.keras.activations.sigmoid)\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "\n",
        "#model.compile(loss= 'binary_crossentropy', metrics=['accuracy'], optimizer=tf.keras.optimizers.SGD(learning_rate=0.5))\n",
        "model.compile(loss= 'binary_crossentropy', optimizer=tf.keras.optimizers.SGD(learning_rate=0.5))\n",
        "\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "HgR8oD2z21SJ",
        "outputId": "0b6eff90-4157-47ec-812b-25a17f10378b"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"AND_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"AND_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_45 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3\u001b[0m (12.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> (12.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3\u001b[0m (12.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> (12.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=100, batch_size=1, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOIIKDb6Cfu8",
        "outputId": "6a37779c-f0d2-4272-be91-ef8d81340ccf"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cf1310e6a10>"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_y = model.predict(np.array([[0,0],[0,1],[1,0],[1,1]]))\n",
        "predicted_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKuyrm7snbah",
        "outputId": "0b3b78f5-3220-470e-a7ba-4c9ba27d9a77"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0011442 ],\n",
              "       [0.08637983],\n",
              "       [0.08665108],\n",
              "       [0.88675505]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Porta lógica XOR e redes multicamadas\n",
        "\n",
        "Primeiramente vamos criar e embaralhar um dataset para a porta XOR"
      ],
      "metadata": {
        "id": "LLTPnuKRsodL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "XOR_data = np.array([[0,0,0],[0,1,1],[1,0,1],[1,1,0]], dtype=np.float64)\n",
        "X_xor, y_xor = XOR_data[:,:2], XOR_data[:,2]\n",
        "X_xor, y_xor = shuffle_in_unison(X_xor, y_xor)\n",
        "X_xor, y_xor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD49yFRytuWJ",
        "outputId": "dd887552-68f4-448a-bc4d-694d5a409396"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0.],\n",
              "        [1., 1.],\n",
              "        [0., 1.],\n",
              "        [1., 0.]]),\n",
              " array([0., 0., 1., 1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Formato de entrada da rede\n",
        "X_input = tf.keras.Input(shape=(X_xor.shape[1],))\n",
        "\n",
        "#Formato da única camada de saída\n",
        "y_pred= tf.keras.layers.Dense(units=1, activation='sigmoid', kernel_initializer=\"zeros\", use_bias='yes')(X_input)\n",
        "\n",
        "#Criando o modelo com os formatos de entrada e saída\n",
        "model2 = tf.keras.Model(inputs=X_input, outputs=y_pred, name='XOR_model')\n",
        "\n",
        "#model.compile(loss= 'binary_crossentropy', metrics=['accuracy'], optimizer=tf.keras.optimizers.SGD(learning_rate=0.5))\n",
        "model2.compile(loss= 'binary_crossentropy', optimizer=tf.keras.optimizers.SGD(learning_rate=0.5))\n",
        "\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "aE-5XukYw9i-",
        "outputId": "0c846bd6-1590-4aae-a778-0f0881510355"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"XOR_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"XOR_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_46 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3\u001b[0m (12.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> (12.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3\u001b[0m (12.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> (12.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dúvidas\n",
        "1. Normalizar melhora o resultado, por que? Faz com que os pesos sejam menores e mais fáceis de calcular.\n",
        "2. Mudar ativação para linear, piora muito. Por que? Porque o regressor você quer encontrar um valor predito e não um rótulo, logo não tem um condicional e por isso que a ativação linear é uma identidade, um filtro passa-tudo.\n",
        "3. Rodar por mais épocas melhora muito o classificador, mas por que se no exemplo do perceptron feito a mão precisamos de somente 5 épocas? É porque o perceptron feito a mão conseguimos modelar uma não linearidade, a função de ativação de um degrau binário, já para ser computável por diferenciação a ativação sigmoide é a mais adequada mas ela precisa de mais gerações para se aproximar de um degrau binário. A taxa de aprendizagem também apresenta um papel fundamental, quanto maior, menos épocas para convergir, no entanto maior o risco de cair em um mínimo local (não é o nosso caso pois o conjunto de dados e características é muito pequeno), outro risco também é se isntabilizar e não convergir. Mais sobre o learning rate [aqui](https://www.jeremyjordan.me/nn-learning-rate/)\n"
      ],
      "metadata": {
        "id": "UJnjx9UVvyLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Anotações\n",
        "\n",
        "* Classificador para categorizar de 0 a 1 (ou nos rótulos disponíveis)\n",
        "* Regressor linear que classificar de 0 a Infinito, \"estou medindo o quanto eu erro\"\n",
        "* Regressão logística (é um classificador) otimiza os casos próximos da reta de decisão (casos duvidoso) e não se importa para dados muito distantes da reta. É desenvolvido através de binary crossentrophy (neg log-likehood) e ativação de sigmoide logística."
      ],
      "metadata": {
        "id": "Rd3SIPDkxS2x"
      }
    }
  ]
}